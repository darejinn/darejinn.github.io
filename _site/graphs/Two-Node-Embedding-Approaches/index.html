<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.19.1 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="ko" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Two Node Embedding Approaches - Shallow and NN-based - DaRe_jin’s Blog</title>
<meta name="description" content="  ">


  <meta name="author" content="DaRe_jin">


<meta property="og:type" content="article">
<meta property="og:locale" content="ko">
<meta property="og:site_name" content="DaRe_jin's Blog">
<meta property="og:title" content="Two Node Embedding Approaches - Shallow and NN-based">
<meta property="og:url" content="http://localhost:4000/graphs/Two-Node-Embedding-Approaches/">


  <meta property="og:description" content="  ">







  <meta property="article:published_time" content="2025-08-11T00:00:00+09:00">



  <meta property="article:modified_time" content="2025-08-11T00:00:00+09:00">



  

  


<link rel="canonical" href="http://localhost:4000/graphs/Two-Node-Embedding-Approaches/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "DaRe_jin",
      "url": "http://localhost:4000/"
    
  }
</script>


  <meta name="google-site-verification" content="google6dd9f38f264894e0.html" />





<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="DaRe_jin's Blog Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


<script type="text/javascript"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
    <!-- start custom head snippets -->
<script data-ad-client="ca-pub-3886880548487088" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->


<!-- insert favicons. use https://realfavicongenerator.net/ -->
<link rel="apple-touch-icon" sizes="180x180" href="/assets/logo.ico/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="96x96" href="/assets/logo.ico/favicon-96x96.png">
<link rel="mask-icon" href="/assets/logo.ico/favicon.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">

<!-- end custom head snippets -->

    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$'] ],
        processEscapes: true,
      }
    });
    MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    </script>
    <script type="text/javascript" async
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          DaRe_jin's Blog
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about/">About Me</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/">Categories</a>
            </li><li class="masthead__menu-item">
              <a href="/tags/">Tags</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16">
            <path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path>
          </svg>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">토글 메뉴</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      


  
    



<nav class="breadcrumbs">
  <ol itemscope itemtype="https://schema.org/BreadcrumbList">
    
    
    
      
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="http://localhost:4000/" itemprop="item"><span itemprop="name">Home</span></a>
          <meta itemprop="position" content="1" />
        </li>
        <span class="sep">/</span>
      
      
        
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/categories/#graphs" itemprop="item"><span itemprop="name">Graphs</span></a>
          <meta itemprop="position" content="2" />
        </li>
        <span class="sep">/</span>
      
    
      
      
        <li class="current">Two Node Embedding Approaches - Shallow and NN-based</li>
      
    
  </ol>
</nav>

  


<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      
        <img src="https://github.com/user-attachments/assets/b9d11a7a-8e27-4c9d-959b-a200897167d6" alt="DaRe_jin" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">DaRe_jin</h3>
    
    
      <div class="author__bio" itemprop="description">
        <p>내실 있는 낙관</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">팔로우</button>
    <ul class="author__urls social-icons">
      

      
        
          
        
          
        
          
        
          
        
          
            <li><a href="https://github.com/darejinn" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
    
      
      
      
      
    
    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">토글 메뉴</label>
  <ul class="nav__items">
    
      <li>
        
          <span class="nav__sub-title">AI</span>
        

        
        <ul>
          
            <li><a href="/categories/Papers/">Papers</a></li>
          
            <li><a href="/categories/Graphs/">Graphs</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Medical</span>
        

        
        <ul>
          
            <li><a href="/categories/Projects/">Projects</a></li>
          
            <li><a href="/categories/Bioinformatics/">Bioinformatics</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Diary</span>
        

        
        <ul>
          
            <li><a href="/categories/Thoughts/">Thoughts</a></li>
          
            <li><a href="/categories/Finance/">Finance</a></li>
          
            <li><a href="/categories/Bridges/">Bridges</a></li>
          
        </ul>
        
      </li>
    
  </ul>
</nav>

    
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Two Node Embedding Approaches - Shallow and NN-based">
    <meta itemprop="description" content="">
    <meta itemprop="datePublished" content="2025-08-11T00:00:00+09:00">
    <meta itemprop="dateModified" content="2025-08-11T00:00:00+09:00">

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Two Node Embedding Approaches - Shallow and NN-based
</h1>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On This Page</h4></header>
              <ul class="toc__menu">
  <li><a href="#introduction">Introduction</a>
    <ul>
      <li><a href="#review--learning-framework">Review : Learning framework</a></li>
    </ul>
  </li>
  <li><a href="#two-node-embedding-approaches">Two Node Embedding Approaches</a>
    <ul>
      <li><a href="#1-shallow-embedding">1. Shallow embedding</a>
        <ul>
          <li><a href="#1-1-factorization-based-approaches">1-1. Factorization-based approaches</a></li>
          <li><a href="#1-2-random-walk-based-approaches">1-2. Random walk-based approaches</a></li>
        </ul>
      </li>
      <li><a href="#2-nn-based-embedding">2. NN-based embedding</a>
        <ul>
          <li><a href="#2-1-neighborhood-autoencoder-dngr-sdne">2-1. Neighborhood Autoencoder (DNGR, SDNE)</a></li>
          <li><a href="#2-2-neighborhood-aggregation-gcngraphsagegat">2-2. Neighborhood Aggregation (GCN/GraphSAGE/GAT)</a></li>
        </ul>
      </li>
      <li><a href="#마무리하며">마무리하며</a>
        <ul>
          <li><a href="#첨언">첨언</a></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

            </nav>
          </aside>
        
        <hr />

<h1 id="introduction">Introduction</h1>

<p><a href="https://darejinn.github.io/graphs/Representation-Learning-on-Graphs/">앞선 글</a> 에서 설명했듯, Graph Representation Learning은 그래프의 요소(node, edge, subgraph)를 저차원 벡터로 매핑하는 method이다. 많은 survey가 여러 요소 중에서도 <strong>node embedding</strong>에 초점을 맞추는 이유는 다음과 같다.</p>

<ol>
  <li>
    <p><strong>Edge/subgraph embedding이 node embedding의 후처리로 귀결</strong>되는 경우가 많다.</p>

    <p>예를 들어</p>
    <ul>
      <li>edge $(v_i,v_j)\in E$에 대해 node embedding $\mathbf{z}_i,\mathbf{z}_j$가 주어지면 hadamard/mean/weighted-L1·L2 같은 이항 연산으로 아래처럼 edge embedding을 만든다.</li>
    </ul>

\[\mathbf{z}_{(i,j)}=\mathbf{z}_i\odot\mathbf{z}_j\]

    <ul>
      <li>subgraph $\mathcal{G}[\mathcal{S}]$의 embedding도 보통 $\mathcal{S}\subset\mathcal{V}$에 포함된 node embedding을 집계(average/attention 등)해서 아래와 같이 얻는다.</li>
    </ul>

\[\mathbf{z}_{\text{subgraph}}=\frac{1}{|\mathcal{S}|}\sum_{v_i\in\mathcal{S}}\mathbf{z}_i\]
  </li>
  <li>
    <p>Edge/Subgraph embedding을 직접 학습하더라도 절차는 <strong>node embedding 학습과 본질적으로 유사</strong>하다.</p>
    <ul>
      <li>예를 들어 타깃 subgraph의 모든 node에 연결된 dummy node를 추가하고 그 node의 embedding을 학습 대상으로 두면 사실상 node embedding 학습과 거의 동일한 형태가 된다.</li>
    </ul>
  </li>
</ol>

<p>따라서 node embedding을 이해하면 edge/subgraph embedding도 같은 틀 안에서 상당 부분 설명된다. 이하에서는 <strong>encoder를 어떻게 정의하는지</strong>에 따라 node embedding을 <strong>shallow embedding</strong>과 <strong>NN-based embedding</strong>으로 비교해 정리한다. 본 글은 <a href="https://arxiv.org/abs/1709.05584">“<em>Representation Learning on Graphs</em>” (2017) </a>에서 제시한 개념을 바탕으로 필자의 해석을 더해 작성하였다.</p>

<hr />

<h2 id="review--learning-framework"><em>Review : Learning framework</em></h2>

<p><em>‘그래프에서 가까운 node는 embedding 공간에서도 가깝다’</em>는 <strong>structural assumption</strong> 아래, 다음 세 가지를 설계한다.</p>

<ul>
  <li>
    <p><strong>그래프 상의 유사도 $s_G$</strong></p>

\[s_G:\mathcal{V}\times\mathcal{V}\to\mathbb{R}^+,\qquad
s_G(i,j)\in\{A_{ij},\ k\text{-hop},\ \text{랜덤워크 공출현확률}\}\]
  </li>
  <li>
    <p><strong>Embedding 공간의 decoder $\mathrm{DEC}$</strong></p>

\[\mathrm{DEC}:\mathbb{R}^d\times\mathbb{R}^d\to\mathbb{R},\quad
\text{예: }\ \mathbf{z}_i^\top\mathbf{z}_j,\ -\lVert\mathbf{z}_i-\mathbf{z}_j\rVert_2^2,\ \sigma(\mathbf{z}_i^\top\mathbf{z}_j)\]
  </li>
  <li>
    <p><strong>Encoder $\mathrm{ENC}$와 loss function(learning objective)</strong></p>
  </li>
</ul>

\[\mathbf{z}_i=\mathrm{ENC}(v_i),\qquad
  \mathcal{L}=\sum_{(i,j)\in\mathcal{D}}\ell\!\Big(\mathrm{DEC}(\mathbf{z}_i,\mathbf{z}_j),\ s_G(i,j)\Big)\]

<p>여기서 <strong>structural assumption은 ‘무엇을 가깝게 유지할지’에 대한 inductive bias,</strong> 즉 <strong>네트워크 구조에 관한 모델의 prior</strong>다.</p>

<p>$s_G$를 어떻게 정의할지(무엇을 ‘유사’로 볼지), $\mathrm{DEC}$를 어떻게 둘지(embedding에서 유사를 어떻게 수치화할지), $\mathrm{ENC}$를 어떻게 설계할지(그 유사를 재현하도록 표현을 만들지)에 이 가정이 명시적·암묵적으로 들어 있다.</p>

<hr />
<p><br />
<br /></p>

<h1 id="two-node-embedding-approaches">Two Node Embedding Approaches</h1>
<hr />
<p>위와 같은 $\mathrm{ENC}$–$s_G$–$\mathrm{DEC}$ 프레임워크 안에서, <strong>학습이 일어나는 층위</strong>에 따라 접근을 두 가지로 나눌 수 있다.</p>

<ul>
  <li><strong>Shallow</strong> : 미리 정한 $s_G$에 맞춰 <strong>node별 embedding 자체</strong>를 <strong>직접</strong> 최적화한다.</li>
  <li><strong>NN-based</strong>: <strong>유사도를 만들어내는 연산</strong>(autoencoder, message passing)를 학습해 embedding을 <strong>간접</strong>적으로 만든다. 파라미터는 <strong>node 간 공유</strong>된다.</li>
</ul>

<hr />

<h2 id="1-shallow-embedding"><em>1. Shallow embedding</em></h2>

<p>Shallow embedding은 <strong>node ID를 임베딩 행렬의 열(column)에 직접 매핑</strong>하는 방식이다.</p>

\[Z \in \mathbb{R}^{d \times |\mathcal{V}|}, \qquad \mathrm{ENC}(v_i) = Z_{\cdot i} = \mathbf{z}_i\]

<p>Encoder 구조가 단순하기 때문에, 무엇을 보존할지에 대한 선택이 거의 전적으로 <strong>그래프 상의 유사도 정의 $s_G$와 Decoder</strong> 설계에 담긴다.</p>

<hr />

<h3 id="1-1-factorization-based-approaches"><em>1-1. Factorization-based approaches</em></h3>

<ul>
  <li>
    <p><strong>무엇을 보존할지 ($s_G$ 설정)</strong><br />
유사도 행렬 $S$는 인접성, 근접성, 전파 도달성 등 다양한 그래프 속성을 반영하도록 정의할 수 있다. 예시는 다음과 같다.</p>

\[S = A \quad \text{(adjacency)}, \qquad
S = A^k \quad (k\text{-hop}),
\qquad
S = \text{Katz}, \ \text{RPR}, \ \text{Jaccard} \ \text{등}\]

    <p>$S$의 정의에 따라, embedding이 강조하는 구조적 특성(커뮤니티, 국소 근접성, 전파 가능성 등)이 달라진다.</p>
  </li>
  <li>
    <p><strong>Embedding에서 어떻게 읽을지 (Decoder)</strong></p>

    <p>대표적인 Decoder 정의는 다음과 같다.</p>

\[\mathrm{DEC}(\mathbf{z}_i, \mathbf{z}_j) = \mathbf{z}_i^\top \mathbf{z}_j
\quad \text{또는} \quad- \lVert \mathbf{z}_i - \mathbf{z}_j \rVert_2^2\]
  </li>
  <li>
    <p><strong>Loss function (learning objective)</strong></p>

    <ul>
      <li>
        <p>Decoder가 내적(inner product)일 경우
\(\min_{Z} \ \lVert S - Z^\top Z \rVert_F^2\)</p>
      </li>
      <li>
        <p>Decoder가 음의 유클리드 거리일 경우
\(\sum_{i,j} W_{ij} \lVert \mathbf{z}_i - \mathbf{z}_j \rVert_2^2 
\ = \ 2\, \mathrm{tr}(Z L Z^\top)\)</p>
      </li>
    </ul>
  </li>
</ul>

<hr />

<h3 id="1-2-random-walk-based-approaches"><em>1-2. Random walk-based approaches</em></h3>

<ul>
  <li>
    <p><strong>무엇을 보존할지 ($s_G$ 설정)</strong></p>

    <p>랜덤 워크를 통해 생성한 노드 시퀀스에서 <strong>공출현(co-occurrence) 강도 또는 확률</strong>을 노드 간 유사도로 정의한다.</p>
    <ul>
      <li><strong>DeepWalk</strong>: 편향 없는(unbiased) 랜덤 워크를 사용.</li>
      <li><strong>node2vec</strong>: 하이퍼파라미터 $p, q$로 BFS/DFS 성향을 조절하여, 국소적 조밀성(locality)과 구조적 역할(role) 간의 균형을 조정.</li>
    </ul>
  </li>
  <li>
    <p><strong>Embedding에서 어떻게 읽을지 (Decoder)</strong></p>

    <p>Factorization 기반 방법과 유사하게, 내적 기반 Decoder를 사용하되, <strong>유사도 행렬 S</strong>가 아니라 <strong>랜덤 워크 확률</strong>을 근사하도록 학습한다.<br />
즉, 다음 조건이 만족되도록 embedding을 학습한다.</p>

\[\mathrm{DEC}(\mathbf{z}_i, \mathbf{z}_j)=
\frac{\exp(\mathbf{z}_i^\top \mathbf{z}_j)}
     {\sum_{v_k \in \mathcal{V}} \exp(\mathbf{z}_i^\top \mathbf{z}_k)}
\ \approx \ p_{G,T}(v_j \mid v_i)\]

    <p>여기서 $p_{G,T}(v_j \mid v_i)$는 그래프 $G$에서 노드 $v_i$에서 시작해 길이 $T$의 랜덤 워크를 수행할 때 노드 $v_j$를 방문할 확률이며, 일반적으로 $T \in { 2, \dots, 10 }$ 범위로 설정된다.</p>
  </li>
  <li>
    <p><strong>Loss function (learning objective)</strong></p>

    <p>위 확률 근사를 위해 다음 <strong>cross enthropy loss</strong>을 최소화한다.</p>

\[\mathcal{L} = \sum_{(v_i, v_j) \in D} - \log \left( \mathrm{DEC}(\mathbf{z}_i, \mathbf{z}_j) \right)\]

    <p>여기서 $D$는 각 노드 $v_i$에서 시작하는 랜덤 워크로부터 샘플링된 $(v_i, v_j)$ 쌍들의 집합이다.
그러나 위 식의 분모 계산은 $O(|\mathcal{V}|)$ 시간이 소요되므로, 전체 학습 비용은 $O(|D||\mathcal{V}|)$로 매우 크다. 이를 해결하기 위해:</p>

    <ul>
      <li><strong>DeepWalk</strong>의 경우 : <strong>Hierarchical softmax</strong>를 사용하여, 이진 트리 구조로 정규화 항 계산을 가속한다.</li>
      <li><strong>Node2vec</strong>의 경우: <strong>Negative sampling</strong> 사용하여, 전체 노드 집합 대신 무작위로 선택한 소수의 negative sample로 분모를 근사한다.</li>
    </ul>
  </li>
  <li>
    <p>가장 대표적인 random walk based embedding method를 다루었는데, Deepwalk와 node2vec 외에도 LINE, HARP 등의 다양한 방법이 있다.</p>
  </li>
</ul>

<hr />
<p><br /></p>

<h2 id="2-nn-based-embedding"><em>2. NN-based embedding</em></h2>

<p>Shallow가 node-id만 입력으로 받아 바로 embedding을 lookup하는 것과 달리, NN-based는 <strong>node 특징 $\mathbf{x}_i$와 이웃 $\mathcal{N}(i)$를 입력으로 받아 처리하는 네트워크</strong>를 학습한다.</p>

<h3 id="2-1-neighborhood-autoencoder-dngr-sdne"><em>2-1. Neighborhood Autoencoder (DNGR, SDNE)</em></h3>

<p>각 노드 $i$마다, <strong>이웃 분포(neighborhood distribution)</strong> 를 나타내는 벡터  $\mathbf{s}_i \in \mathbb{R}^{|\mathcal{V}|}$를 생성한 뒤, 이를 <strong>Autoencoder</strong>로 복원한다.
여기서 $\mathbf{s}_i$는 행렬 $S$의 $i$번째 행에 해당하며, $S$는 노드 간 유사도 $s_G(v_i, v_j)$를 담고 있다.<br />
즉, $\mathbf{s}_i$는 노드 $v_i$가 그래프 내 모든 다른 노드와 가지는 유사도를 포함하는 고차원의 벡터다.</p>

<p><strong>Learning objective</strong>는 다음과 같다.</p>

\[\min_{\theta,\phi} \ \sum_i 
\left\lVert
\mathbf{s}_i - \mathrm{DEC}_\phi\big(\mathrm{ENC}_\theta(\mathbf{s}_i)\big)
\right\rVert_2^2\]

<p><br />
Shallow embedding과 달리 <strong>파라미터가 노드 간 공유</strong>되어 연산이 효율적이다. 하지만 입력 차원이 $|\mathcal{V}|$에 고정되어 있어 대규모 그래프 적용이 어려우며, 새로운 그래프에 대한 적용도 제한적이다. ( <strong>transductive</strong> )</p>

<h3 id="2-2-neighborhood-aggregation-gcngraphsagegat"><em>2-2. Neighborhood Aggregation (GCN/GraphSAGE/GAT)</em></h3>

<p><strong>Message Passing</strong>으로 이웃 표현을 aggregate해 자신의 표현과 결합하는 연산을 여러 층 반복한다.</p>

<blockquote>

  <p>참고로, <strong>Message Passing</strong>은 “Neural message passing for quantum chemistry.”논문에서 처음 GNN의 framework를 통합적으로 설명하기 위해 제시한 개념으로, 이후 많은 논문들에서 해당 개념을 차용하여 GNN을 설명하기 시작하였다. 
딥마인드의 Petar Veličković는 최신의 ‘beyond message passing’으로 여겨졌던 GNN 기법도 본질적으로 message passing framework으로 모두 설명할 수 있다고  <a href="https://arxiv.org/abs/2202.11097">“Message passing all the way up” </a> 에서 주장하였다.</p>

</blockquote>

<p><strong>연산 과정은 다음과 같다.</strong></p>

\[\mathbf{h}_i^{(0)} = \mathbf{x}_i, \quad
\mathbf{h}_i^{(k)} = \mathrm{COMBINE}^{(k)}\Big(
  \mathbf{h}_i^{(k-1)}, \
  \mathrm{AGG}^{(k)}\{\mathbf{h}_j^{(k-1)} : j \in \mathcal{N}(i)\}
\Big), \quad
\mathbf{z}_i = \mathbf{h}_i^{(K)}\]

<ol>
  <li>초기 임베딩은 입력 특징 $\mathbf{x}_i$로 설정한다.</li>
  <li>각 단계에서 이웃 노드 임베딩을 집계($\mathrm{AGG}$)한다.</li>
  <li>집계된 이웃 표현과 자신의 이전 단계 표현을 결합($\mathrm{COMBINE}$)한다.</li>
  <li>이 과정을 $K$번 반복하여 최종 임베딩 $\mathbf{z}_i$를 얻는다.</li>
</ol>

<p>위 encoder 연산에서 COMBINE function과 AGG function을 어떻게 정의하는지에 따라 GNN의 세부 방법론(GCN, GraphSAGE, GAT 등) 들이 나누어진다.</p>

<p><br /></p>

<p><strong>GNN은 구조에 대한 연산(structural assumption)을 $\mathrm{ENC}$가 담당하므로, $\mathrm{DEC}$와  loss function(learning objective) 은 태스크에 맞춰 유연하게 설정할 수 있다.</strong></p>
<ul>
  <li>링크 예측 : $\mathrm{DEC}(\mathbf{z}_i,\mathbf{z}_j)=\sigma(\mathbf{z}_i^\top\mathbf{z}_j)$, negative sampling</li>
  <li>node 분류 : $\hat{\mathbf{y}}_i=\mathrm{softmax}(W\mathbf{z}_i)$, cross-enthropy</li>
  <li>그래프/subgraph 관련 supervised task: $\mathrm{READOUT}$으로 node embedding을 post processing한 후 태스크별 $\mathrm{DEC}$ 사용</li>
</ul>

<p><br /></p>

<p>이 방법은 가장 진보한, 현재에도 활발히 연구되고 있는 graph representation 방식으로, 흔히 GNN을 이야기하면 보통 neighborhood aggregation을 바탕으로 한 이 message passing을 상정한다.</p>

<p>Neighborhood Autoencoder 방법과 마찬가지로 <strong>파라미터 공유</strong>가 이루어지며, 순차적으로 주변 정보를 aggregate하므로 모델 크기가 ‘그래프 크기와 관계 없이’ 효율적으로 작게 유지된다. <strong>Node feature/edge weight</strong> 등 그래프 관련 meta information을 자연스럽게 활용할 수 있으며, 처음 보는 그래프에도 적용이 수월하다. ( <strong>inductive</strong> )</p>

<hr />

<h2 id="마무리하며">마무리하며</h2>

<ul>
  <li>
    <p>Graph representation learning의 framework는,
<strong>(1) 무엇을 유사로 볼지($s_G$)</strong>, <strong>(2) embedding에서 그 유사를 어떻게 읽어낼지($\mathrm{DEC}$)</strong>, <strong>(3) 그 유사를 재현하도록 어떤 연산을 학습할지($\mathrm{ENC}$)</strong> 를 설정(<strong>structural assumption</strong>) 하는 것이 핵심이다.</p>

    <ul>
      <li><strong>Shallow</strong>는 <strong>(1)</strong> 유사도를 정의하고(S 혹은 공출현확률) 그에 맞춰 <strong>(2)</strong> embedding 열의 내적이 비슷하도록 <strong>(3)</strong> embedding 열을 각 node id마다 따로따로 lookup한다.</li>
      <li><strong>Neighborhood Autoencoder</strong>는 <strong>(1)</strong> node마다 이웃 node의 정보를 나타내는 $\mathbf{s}_i$를 정의해, <strong>(3)</strong> 오토인코더를 이용해 <strong>(2)</strong> $\mathbf{s}_i$를 복원하도록 효율적으로 학습한다.</li>
      <li><strong>Neighborhood Aggregation(GNN)</strong> 은 <strong>(1)(3)</strong> “무엇을 보존할지”가 <strong>message passing network</strong>에 녹아 있으며, 태스크에 따라 <strong>(2)</strong> $\mathrm{DEC}$/loss를 유연하게 붙일 수 있다.</li>
    </ul>
  </li>
</ul>

<p>구체적 방법론과 수식 유도는 후속 글에서 더 다룰 예정이다.</p>

<h3 id="첨언">첨언</h3>

<ol>
  <li>두 approach로 node embedding method를 나누어 설명하였지만, 두 approach는 배타적이지 않으며 해당하지 않는 예외도 존재한다. 가령 random walk 기반 sampling을 한 뒤 neural network를 학습시키는 방법도 있다. 또한 message passing의 fundamental한 한계를 지적하며 아예 새로운 framework를 제안하는 연구들도 있다. <a href="https://arxiv.org/pdf/2501.18739"><em>(ex. 랜덤워크를 통해 얻어낸 pattetn을 transformer에 넣는 방법을 제안한 최신 논문이다</em>)</a></li>
  <li><a href="https://arxiv.org/abs/1709.05584">“<em>Representation Learning on Graphs</em>” (2017) </a>의 내용을 주로 참고한 이유는, 교신저자께서 graph machine learning의 대가이신, CS224W의 레즈코벡 교수님이시며, 특정 태스크(community detection, link prediction)나 메소드에 치중하지 않고 traditional method부터 GNN까지의 전반적인 개념을 한 프레임워크로 설명하시었기 때문이다. (<em>서울대학교 컴퓨터공학부 김선 교수님께서도 그래프 마이닝 강의 중, 해당 survey 논문을 교본으로 사용하셨다.</em>)</li>
  <li>본 글에서는 시간축에 따라 변화하는 dynamic graph는 다루지 않았다.</li>
  <li>학습이 일어나는 순방향 framework에 초점을 맞추었지만, 사실 최적화 방법도 매우 다양하다. 가령 라플라시안 행렬 분해는 목적함수를 최소화하는 문제를 일반화된 고윳값 문제의 해를 찾는 방법으로 해결한다. 신경망 기반 GRL은 일반적으로 gradient descent로 loss를 줄이는 방향으로 parameter를 update한다.</li>
</ol>

        
      
        <!-- 포스팅 후 광고 넣기 , 출처 : https://shryu8902.github.io/jekyll/adsense/ -->
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <!-- gpage.taeyoung96 -->
        <div align="center" style="margin: 1em 0;">
          <ins class="adsbygoogle"
              style="display:block"
              data-ad-client="ca-pub-3886880548487088"
              data-ad-slot="7487712129"
              data-ad-format="auto"
              data-full-width-responsive="true"></ins>
        </div>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>

      </section>

      <footer class="page__meta">
        
        
  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> 태그: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="/tags/#graphs" class="page__taxonomy-item" rel="tag">Graphs</a><span class="sep">, </span>
    
      
      
      <a href="/tags/#representation-learning" class="page__taxonomy-item" rel="tag">Representation learning</a>
    
    </span>
  </p>




  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> 카테고리: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="/categories/#graphs" class="page__taxonomy-item" rel="tag">Graphs</a>
    
    </span>
  </p>


        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> 업데이트:</strong> <time datetime="2025-08-11">August 11, 2025</time></p>
        
      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title">공유하기</h4>
  

  <a href="https://twitter.com/intent/tweet?text=Two+Node+Embedding+Approaches+-+Shallow+and+NN-based%20http%3A%2F%2Flocalhost%3A4000%2Fgraphs%2FTwo-Node-Embedding-Approaches%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="공유하기 Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2Fgraphs%2FTwo-Node-Embedding-Approaches%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="공유하기 Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Fgraphs%2FTwo-Node-Embedding-Approaches%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="공유하기 LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/thoughts/08.-%EC%9A%B0%EC%97%B0-%EC%86%8D%EC%9D%98-%ED%95%84%EC%97%B0/" class="pagination--pager" title="우연 속의 필연
">이전</a>
    
    
      <a href="/projects/AI_Report/" class="pagination--pager" title="[Experience] A 서비스를 런칭하며
">다음</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">최근 포스팅 목록</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="" alt="">
      </div>
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/thoughts/10.-%EC%82%AC%EB%9E%8C%EB%8B%A4%EC%9B%80(2)/" rel="permalink">사람다움(2)
</a>
      
    </h2>
  <!--
    devinlife comments :
        아키이브 싱글 페이지(ex. 카테고리)에 각 포스트 제목 밑에 Updated 시간 표기
        기존에는 read_time이 표기. read_time -> date 변경
    
  -->
  

<p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> September 21 2025</p>

    <p class="archive__item-excerpt" itemprop="description">
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="" alt="">
      </div>
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/thoughts/09.-%EC%84%AC%EC%84%B8%ED%95%9C-%EC%86%94%EC%A7%81%ED%95%A8/" rel="permalink">섬세한 솔직함
</a>
      
    </h2>
  <!--
    devinlife comments :
        아키이브 싱글 페이지(ex. 카테고리)에 각 포스트 제목 밑에 Updated 시간 표기
        기존에는 read_time이 표기. read_time -> date 변경
    
  -->
  

<p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> September 21 2025</p>

    <p class="archive__item-excerpt" itemprop="description">
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="" alt="">
      </div>
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/finance/%EC%9E%A5%EA%B8%B0-%ED%9D%90%EB%A6%84/" rel="permalink">장기 흐름
</a>
      
    </h2>
  <!--
    devinlife comments :
        아키이브 싱글 페이지(ex. 카테고리)에 각 포스트 제목 밑에 Updated 시간 표기
        기존에는 read_time이 표기. read_time -> date 변경
    
  -->
  

<p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> August 21 2025</p>

    <p class="archive__item-excerpt" itemprop="description">
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="" alt="">
      </div>
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/bridges/%EA%B2%A9%EC%9D%84-%EA%B0%96%EC%B6%A4/" rel="permalink">격을 갖춤
</a>
      
    </h2>
  <!--
    devinlife comments :
        아키이브 싱글 페이지(ex. 카테고리)에 각 포스트 제목 밑에 Updated 시간 표기
        기존에는 read_time이 표기. read_time -> date 변경
    
  -->
  

<p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> August 21 2025</p>

    <p class="archive__item-excerpt" itemprop="description">
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="검색어를 입력하세요..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- gpage.taeyoung96 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-3886880548487088"
     data-ad-slot="7487712129"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>팔로우:</strong></li>
    

    
      
        
      
        
      
        
          <li><a href="https://github.com/darejinn" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
      
        
      
        
      
    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> 피드</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2025 DaRe_jin. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script src="https://kit.fontawesome.com/4eee35f757.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




    <script>
  'use strict';

  (function() {
    var commentContainer = document.querySelector('#utterances-comments');

    if (!commentContainer) {
      return;
    }

    var script = document.createElement('script');
    script.setAttribute('src', 'https://utteranc.es/client.js');
    script.setAttribute('repo', 'darejinn/darejinn.github.io');
    script.setAttribute('issue-term', 'pathname');
    script.setAttribute('theme', 'github-light');
    script.setAttribute('crossorigin', 'anonymous');

    commentContainer.appendChild(script);
  })();
</script>

  




<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      extensions: ["tex2jax.js"],
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
      },
      "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>

  </body>
</html>
